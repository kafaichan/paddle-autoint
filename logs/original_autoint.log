(tensorflow) D:\workspace\AutoInt>python -u train.py --data "Criteo" --blocks 3 --heads 2  --block_shape "[64, 64, 64]" --is_save "True" --save_path "./test_code/Criteo/b3h2_64x64x64/" --field_size 39  --run_times 1 --data_path "./Dataprocess/Criteo/" --epoch 3 --has_residual "True"  --has_wide "False" --batch_size 1024 --deep_layers=[400,400,400]
{'blocks': 3, 'block_shape': [64, 64, 64], 'heads': 2, 'embedding_size': 16, 'dropout_keep_prob': [1, 1, 0.5], 'epoch': 3, 'batch_size': 1024, 'learning_rate': 0.001, 'learning_rate_wide': 0.001, 'optimizer_type': 'adam', 'l2_reg': 0.0, 'random_seed': 2018, 'save_path': './test_code/Criteo/b3h2_64x64x64/', 'field_size': 39, 'loss_type': 'logloss', 'verbose': 1, 'run_times': 1, 'is_save': True, 'greater_is_better': False, 'has_residual': True, 'has_wide': False, 'deep_layers': [400, 400, 400], 'batch_norm': 0, 'batch_norm_decay': 0.995, 'data': 'Criteo', 'data_path': './Dataprocess/Criteo/'}
**************
run time : 1
WARNING:tensorflow:From C:\Users\kafaichan\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
D:\workspace\AutoInt\model.py:64: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  Q = tf.layers.dense(queries, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:65: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  K = tf.layers.dense(keys, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:66: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  V = tf.layers.dense(values, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:68: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  V_res = tf.layers.dense(values, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:86: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.
  weights = tf.layers.dropout(weights, rate=1-dropout_keep_prob,
2022-08-19 22:25:44.187005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-08-19 22:25:46.253257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9628 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1
2022-08-19 22:25:46.298672: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
total parameters :16595090
extra parameters : 611714
epoch 1, file 3
[1-1] model saved!. Valid loss is improved from 1.0000 to 0.4600
[1-1] train-result=0.8073, train-logloss=0.4446, valid-result=0.7894, valid-logloss=0.4600 [402.5 s]
epoch 1, file 4
[1-2] model saved!. Valid loss is improved from 0.4600 to 0.4574
[1-2] train-result=0.8105, train-logloss=0.4440, valid-result=0.7946, valid-logloss=0.4574 [403.6 s]
epoch 1, file 5
[1-3] model saved!. Valid loss is improved from 0.4574 to 0.4531
[1-3] train-result=0.8134, train-logloss=0.4399, valid-result=0.7979, valid-logloss=0.4531 [876.6 s]
epoch 1, file 6
[1-4] model saved!. Valid loss is improved from 0.4531 to 0.4511
[1-4] train-result=0.8150, train-logloss=0.4383, valid-result=0.8002, valid-logloss=0.4511 [813.3 s]
epoch 1, file 7
[1-5] model saved!. Valid loss is improved from 0.4511 to 0.4497
[1-5] train-result=0.8154, train-logloss=0.4372, valid-result=0.8014, valid-logloss=0.4497 [809.8 s]
epoch 1, file 8
WARNING:tensorflow:From C:\Users\kafaichan\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
[1-6] model saved!. Valid loss is improved from 0.4497 to 0.4488
[1-6] train-result=0.8162, train-logloss=0.4362, valid-result=0.8023, valid-logloss=0.4488 [808.6 s]
epoch 1, file 9
[1-7] model saved!. Valid loss is improved from 0.4488 to 0.4475
[1-7] train-result=0.8169, train-logloss=0.4354, valid-result=0.8036, valid-logloss=0.4475 [811.5 s]
epoch 1, file 10
[1-8] model saved!. Valid loss is improved from 0.4475 to 0.4471
[1-8] train-result=0.8169, train-logloss=0.4363, valid-result=0.8042, valid-logloss=0.4471 [810.6 s]
epoch 1, time 5736
epoch 2, file 3
[2-1] train-result=0.8210, train-logloss=0.4321, valid-result=0.8041, valid-logloss=0.4475 [806.1 s]
epoch 2, file 4
[2-2] model saved!. Valid loss is improved from 0.4471 to 0.4468
[2-2] train-result=0.8231, train-logloss=0.4295, valid-result=0.8046, valid-logloss=0.4468 [680.4 s]
epoch 2, file 5
[2-3] model saved!. Valid loss is improved from 0.4468 to 0.4462
[2-3] train-result=0.8241, train-logloss=0.4285, valid-result=0.8051, valid-logloss=0.4462 [393.7 s]
epoch 2, file 6
[2-4] model saved!. Valid loss is improved from 0.4462 to 0.4461
[2-4] train-result=0.8247, train-logloss=0.4282, valid-result=0.8051, valid-logloss=0.4461 [394.0 s]
epoch 2, file 7
[2-5] model saved!. Valid loss is improved from 0.4461 to 0.4459
[2-5] train-result=0.8251, train-logloss=0.4276, valid-result=0.8054, valid-logloss=0.4459 [394.2 s]
epoch 2, file 8
[2-6] train-result=0.8255, train-logloss=0.4268, valid-result=0.8057, valid-logloss=0.4459 [391.1 s]
epoch 2, file 9
[2-7] model saved!. Valid loss is improved from 0.4459 to 0.4454
[2-7] train-result=0.8256, train-logloss=0.4268, valid-result=0.8062, valid-logloss=0.4454 [393.5 s]
epoch 2, file 10
[2-8] train-result=0.8266, train-logloss=0.4269, valid-result=0.8064, valid-logloss=0.4457 [391.3 s]
epoch 2, time 3844
epoch 3, file 3
[3-1] train-result=0.8299, train-logloss=0.4223, valid-result=0.8049, valid-logloss=0.4468 [390.9 s]
epoch 3, file 4
[3-2] train-result=0.8317, train-logloss=0.4217, valid-result=0.8048, valid-logloss=0.4464 [391.2 s]
epoch 3, file 5
[3-3] train-result=0.8329, train-logloss=0.4195, valid-result=0.8049, valid-logloss=0.4474 [390.9 s]
epoch 3, file 6
[3-4] train-result=0.8327, train-logloss=0.4196, valid-result=0.8053, valid-logloss=0.4464 [390.5 s]
epoch 3, file 7
[3-5] train-result=0.8338, train-logloss=0.4184, valid-result=0.8052, valid-logloss=0.4467 [391.1 s]
epoch 3, file 8
[3-6] train-result=0.8342, train-logloss=0.4181, valid-result=0.8056, valid-logloss=0.4464 [391.0 s]
epoch 3, file 9
[3-7] train-result=0.8339, train-logloss=0.4183, valid-result=0.8056, valid-logloss=0.4463 [391.2 s]
epoch 3, file 10
[3-8] train-result=0.8336, train-logloss=0.4194, valid-result=0.8057, valid-logloss=0.4468 [391.0 s]
epoch 3, time 3127
start testing!...
restored from ./test_code/Criteo/b3h2_64x64x64/1/
test-result = 0.8065, test-logloss = 0.4451
test_auc [0.8065252927733216]
test_log_loss [0.445123533043696]
avg_auc 0.8065252927733216
avg_log_loss 0.445123533043696



(tensorflow) D:\workspace\AutoInt>python -u train.py --data "Criteo" --blocks 3 --heads 2  --block_shape "[64,64,64]" --is_save "True" --save_path "./test_code/Criteo/b3h2_64x64x64/" --field_size 39  --run_times 1 --data_path "./Dataprocess/Criteo/" --epoch 3 --has_residual "True"  --has_wide "False" --batch_size 1024
{'blocks': 3, 'block_shape': [64, 64, 64], 'heads': 2, 'embedding_size': 16, 'dropout_keep_prob': [1, 1, 0.5], 'epoch': 3, 'batch_size': 1024, 'learning_rate': 0.001, 'learning_rate_wide': 0.001, 'optimizer_type': 'adam', 'l2_reg': 0.0, 'random_seed': 2018, 'save_path': './test_code/Criteo/b3h2_64x64x64/', 'field_size': 39, 'loss_type': 'logloss', 'verbose': 1, 'run_times': 1, 'is_save': True, 'greater_is_better': False, 'has_residual': True, 'has_wide': False, 'deep_layers': None, 'batch_norm': 0, 'batch_norm_decay': 0.995, 'data': 'Criteo', 'data_path': './Dataprocess/Criteo/'}
**************
run time : 1
WARNING:tensorflow:From C:\Users\kafaichan\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
D:\workspace\AutoInt\model.py:64: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  Q = tf.layers.dense(queries, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:65: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  K = tf.layers.dense(keys, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:66: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  V = tf.layers.dense(values, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:68: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  V_res = tf.layers.dense(values, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:86: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.
  weights = tf.layers.dropout(weights, rate=1-dropout_keep_prob,
2022-08-23 19:05:40.640937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-08-23 19:05:41.086951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9628 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1
2022-08-23 19:05:41.118471: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
total parameters :16023889
extra parameters : 40513
epoch 1, file 3
[1-1] model saved!. Valid loss is improved from 1.0000 to 0.4625
[1-1] train-result=0.8077, train-logloss=0.4475, valid-result=0.7896, valid-logloss=0.4625 [411.7 s]
epoch 1, file 4
[1-2] model saved!. Valid loss is improved from 0.4625 to 0.4559
[1-2] train-result=0.8107, train-logloss=0.4418, valid-result=0.7939, valid-logloss=0.4559 [409.6 s]
epoch 1, file 5
[1-3] model saved!. Valid loss is improved from 0.4559 to 0.4543
[1-3] train-result=0.8124, train-logloss=0.4400, valid-result=0.7967, valid-logloss=0.4543 [380.1 s]
epoch 1, file 6
[1-4] model saved!. Valid loss is improved from 0.4543 to 0.4517
[1-4] train-result=0.8141, train-logloss=0.4378, valid-result=0.7994, valid-logloss=0.4517 [381.3 s]
epoch 1, file 7
[1-5] model saved!. Valid loss is improved from 0.4517 to 0.4503
[1-5] train-result=0.8152, train-logloss=0.4369, valid-result=0.8011, valid-logloss=0.4503 [380.4 s]
epoch 1, file 8
WARNING:tensorflow:From C:\Users\kafaichan\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
[1-6] model saved!. Valid loss is improved from 0.4503 to 0.4493
[1-6] train-result=0.8159, train-logloss=0.4369, valid-result=0.8018, valid-logloss=0.4493 [380.8 s]
epoch 1, file 9
[1-7] model saved!. Valid loss is improved from 0.4493 to 0.4485
[1-7] train-result=0.8161, train-logloss=0.4369, valid-result=0.8031, valid-logloss=0.4485 [381.3 s]
epoch 1, file 10
[1-8] model saved!. Valid loss is improved from 0.4485 to 0.4472
[1-8] train-result=0.8167, train-logloss=0.4354, valid-result=0.8039, valid-logloss=0.4472 [381.0 s]
epoch 1, time 3106
epoch 2, file 3
[2-1] train-result=0.8213, train-logloss=0.4317, valid-result=0.8037, valid-logloss=0.4473 [376.3 s]
epoch 2, file 4
[2-2] train-result=0.8223, train-logloss=0.4305, valid-result=0.8038, valid-logloss=0.4475 [375.9 s]
epoch 2, file 5
[2-3] model saved!. Valid loss is improved from 0.4472 to 0.4469
[2-3] train-result=0.8246, train-logloss=0.4278, valid-result=0.8045, valid-logloss=0.4469 [377.5 s]
epoch 2, file 6
[2-4] model saved!. Valid loss is improved from 0.4469 to 0.4466
[2-4] train-result=0.8250, train-logloss=0.4279, valid-result=0.8046, valid-logloss=0.4466 [377.4 s]
epoch 2, file 7
[2-5] model saved!. Valid loss is improved from 0.4466 to 0.4459
[2-5] train-result=0.8257, train-logloss=0.4271, valid-result=0.8053, valid-logloss=0.4459 [377.9 s]
epoch 2, file 8
[2-6] train-result=0.8260, train-logloss=0.4263, valid-result=0.8052, valid-logloss=0.4462 [375.1 s]
epoch 2, file 9
[2-7] train-result=0.8257, train-logloss=0.4271, valid-result=0.8052, valid-logloss=0.4461 [375.0 s]
epoch 2, file 10
[2-8] model saved!. Valid loss is improved from 0.4459 to 0.4459
[2-8] train-result=0.8257, train-logloss=0.4271, valid-result=0.8055, valid-logloss=0.4459 [378.4 s]
epoch 2, time 3013
epoch 3, file 3
[3-1] train-result=0.8297, train-logloss=0.4231, valid-result=0.8044, valid-logloss=0.4470 [375.8 s]
epoch 3, file 4
[3-2] train-result=0.8315, train-logloss=0.4210, valid-result=0.8046, valid-logloss=0.4473 [375.3 s]
epoch 3, file 5
[3-3] train-result=0.8325, train-logloss=0.4205, valid-result=0.8045, valid-logloss=0.4470 [375.1 s]
epoch 3, file 6
[3-4] train-result=0.8336, train-logloss=0.4193, valid-result=0.8044, valid-logloss=0.4469 [375.2 s]
epoch 3, file 7
[3-5] train-result=0.8350, train-logloss=0.4180, valid-result=0.8044, valid-logloss=0.4470 [374.8 s]
epoch 3, file 8
[3-6] train-result=0.8347, train-logloss=0.4190, valid-result=0.8047, valid-logloss=0.4481 [375.3 s]
epoch 3, file 9
[3-7] train-result=0.8350, train-logloss=0.4179, valid-result=0.8046, valid-logloss=0.4468 [375.1 s]
epoch 3, file 10
[3-8] train-result=0.8349, train-logloss=0.4175, valid-result=0.8050, valid-logloss=0.4468 [376.1 s]
epoch 3, time 3002
start testing!...
restored from ./test_code/Criteo/b3h2_64x64x64/1/
test-result = 0.8056, test-logloss = 0.4459
test_auc [0.8055820281918608]
test_log_loss [0.44588187078723834]
avg_auc 0.8055820281918608
avg_log_loss 0.44588187078723834


(tensorflow) D:\workspace\AutoInt>python -u train.py --data "Criteo" --blocks 3 --heads 2  --block_shape "[32,32,32]" --is_save "True" --save_path "./test_code/Criteo/b3h2_32x32x32/" --field_size 39  --run_times 1 --data_path "./Dataprocess/Criteo/" --epoch 3 --has_residual "True"  --has_wide "False" --batch_size 1024
{'blocks': 3, 'block_shape': [32, 32, 32], 'heads': 2, 'embedding_size': 16, 'dropout_keep_prob': [1, 1, 0.5], 'epoch': 3, 'batch_size': 1024, 'learning_rate': 0.001, 'learning_rate_wide': 0.001, 'optimizer_type': 'adam', 'l2_reg': 0.0, 'random_seed': 2018, 'save_path': './test_code/Criteo/b3h2_32x32x32/', 'field_size': 39, 'loss_type': 'logloss', 'verbose': 1, 'run_times': 1, 'is_save': True, 'greater_is_better': False, 'has_residual': True, 'has_wide': False, 'deep_layers': None, 'batch_norm': 0, 'batch_norm_decay': 0.995, 'data': 'Criteo', 'data_path': './Dataprocess/Criteo/'}
**************
run time : 1
WARNING:tensorflow:From C:\Users\kafaichan\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
D:\workspace\AutoInt\model.py:64: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  Q = tf.layers.dense(queries, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:65: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  K = tf.layers.dense(keys, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:66: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  V = tf.layers.dense(values, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:68: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  V_res = tf.layers.dense(values, num_units, activation=tf.nn.relu)
D:\workspace\AutoInt\model.py:86: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.
  weights = tf.layers.dropout(weights, rate=1-dropout_keep_prob,
2022-08-23 08:04:07.576819: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-08-23 08:04:09.549429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9628 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1
2022-08-23 08:04:09.586441: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
total parameters :15995441
extra parameters : 12065
epoch 1, file 3
[1-1] model saved!. Valid loss is improved from 1.0000 to 0.4607
[1-1] train-result=0.8068, train-logloss=0.4461, valid-result=0.7892, valid-logloss=0.4607 [327.2 s]
epoch 1, file 4
[1-2] model saved!. Valid loss is improved from 0.4607 to 0.4564
[1-2] train-result=0.8101, train-logloss=0.4425, valid-result=0.7935, valid-logloss=0.4564 [323.4 s]
epoch 1, file 5
[1-3] model saved!. Valid loss is improved from 0.4564 to 0.4533
[1-3] train-result=0.8130, train-logloss=0.4396, valid-result=0.7970, valid-logloss=0.4533 [322.8 s]
epoch 1, file 6
[1-4] model saved!. Valid loss is improved from 0.4533 to 0.4521
[1-4] train-result=0.8135, train-logloss=0.4388, valid-result=0.7983, valid-logloss=0.4521 [323.1 s]
epoch 1, file 7
[1-5] model saved!. Valid loss is improved from 0.4521 to 0.4510
[1-5] train-result=0.8142, train-logloss=0.4378, valid-result=0.7999, valid-logloss=0.4510 [323.0 s]
epoch 1, file 8
WARNING:tensorflow:From C:\Users\kafaichan\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
[1-6] model saved!. Valid loss is improved from 0.4510 to 0.4507
[1-6] train-result=0.8149, train-logloss=0.4376, valid-result=0.8008, valid-logloss=0.4507 [322.6 s]
epoch 1, file 9
[1-7] model saved!. Valid loss is improved from 0.4507 to 0.4492
[1-7] train-result=0.8149, train-logloss=0.4373, valid-result=0.8017, valid-logloss=0.4492 [322.5 s]
epoch 1, file 10
[1-8] model saved!. Valid loss is improved from 0.4492 to 0.4483
[1-8] train-result=0.8154, train-logloss=0.4370, valid-result=0.8028, valid-logloss=0.4483 [322.4 s]
epoch 1, time 2586
epoch 2, file 3
[2-1] train-result=0.8191, train-logloss=0.4338, valid-result=0.8026, valid-logloss=0.4489 [320.6 s]
epoch 2, file 4
[2-2] train-result=0.8215, train-logloss=0.4313, valid-result=0.8032, valid-logloss=0.4486 [320.6 s]
epoch 2, file 5
[2-3] model saved!. Valid loss is improved from 0.4483 to 0.4477
[2-3] train-result=0.8225, train-logloss=0.4300, valid-result=0.8034, valid-logloss=0.4477 [323.2 s]
epoch 2, file 6
[2-4] train-result=0.8227, train-logloss=0.4303, valid-result=0.8035, valid-logloss=0.4478 [320.4 s]
epoch 2, file 7
[2-5] model saved!. Valid loss is improved from 0.4477 to 0.4475
[2-5] train-result=0.8229, train-logloss=0.4295, valid-result=0.8039, valid-logloss=0.4475 [322.7 s]
epoch 2, file 8
[2-6] model saved!. Valid loss is improved from 0.4475 to 0.4470
[2-6] train-result=0.8236, train-logloss=0.4295, valid-result=0.8043, valid-logloss=0.4470 [323.1 s]
epoch 2, file 9
[2-7] train-result=0.8236, train-logloss=0.4285, valid-result=0.8044, valid-logloss=0.4472 [320.5 s]
epoch 2, file 10
[2-8] train-result=0.8243, train-logloss=0.4294, valid-result=0.8047, valid-logloss=0.4475 [320.3 s]
epoch 2, time 2571
epoch 3, file 3
[3-1] train-result=0.8270, train-logloss=0.4255, valid-result=0.8041, valid-logloss=0.4473 [320.6 s]
epoch 3, file 4
[3-2] train-result=0.8281, train-logloss=0.4244, valid-result=0.8039, valid-logloss=0.4478 [321.4 s]
epoch 3, file 5
[3-3] train-result=0.8296, train-logloss=0.4237, valid-result=0.8038, valid-logloss=0.4476 [320.7 s]
epoch 3, file 6
[3-4] train-result=0.8297, train-logloss=0.4232, valid-result=0.8036, valid-logloss=0.4477 [320.5 s]
epoch 3, file 7
[3-5] train-result=0.8301, train-logloss=0.4220, valid-result=0.8040, valid-logloss=0.4479 [320.7 s]
epoch 3, file 8
[3-6] train-result=0.8305, train-logloss=0.4223, valid-result=0.8041, valid-logloss=0.4473 [320.7 s]
epoch 3, file 9
[3-7] train-result=0.8310, train-logloss=0.4218, valid-result=0.8042, valid-logloss=0.4472 [320.1 s]
epoch 3, file 10
[3-8] train-result=0.8309, train-logloss=0.4218, valid-result=0.8043, valid-logloss=0.4471 [320.4 s]
epoch 3, time 2565
start testing!...
restored from ./test_code/Criteo/b3h2_32x32x32/1/
test-result = 0.8044, test-logloss = 0.4469
test_auc [0.8044202542886356]
test_log_loss [0.4468842128870424]
avg_auc 0.8044202542886356
avg_log_loss 0.4468842128870424